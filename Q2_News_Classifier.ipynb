{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2: News Categorization with Naive Bayes\n",
    "\n",
    "Building three Multinomial Naive Bayes classifiers to categorize news articles.\n",
    "\n",
    "Assignment parts:\n",
    "- Parse RDF/XML ontology\n",
    "- Train models using headlines, descriptions, and combined features\n",
    "- Evaluate and compare performance\n",
    "- Save best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rdflib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Parse RDF Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=N15a2b9779f4a4f7e986ab897203f513e (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = rdflib.Graph()\n",
    "graph.parse('News_Categorizer_RDF.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 9999 articles\n",
      "Sample headline: Mariano Rivera Sand Sculpture: Rays Give Yankees Closer Present (VIDEO)\n",
      "Sample category: SPORTS\n"
     ]
    }
   ],
   "source": [
    "# Extract article data correctly by grouping by subject\n",
    "articles = {}\n",
    "\n",
    "# Extract article data from RDF triples\n",
    "for subject, predicate, obj in graph:\n",
    "    pred_str = str(predicate)\n",
    "    subj_str = str(subject)\n",
    "\n",
    "    # Group all properties by article subject \n",
    "    if subj_str not in articles:\n",
    "        articles[subj_str] = {}\n",
    "\n",
    "    # Match exact predicate URIs\n",
    "    if pred_str.endswith('#headline'):\n",
    "        articles[subj_str]['headline'] = str(obj)\n",
    "    elif pred_str.endswith('#short_description'):\n",
    "        articles[subj_str]['description'] = str(obj)\n",
    "    elif pred_str.endswith('#category'):\n",
    "        articles[subj_str]['category'] = str(obj)\n",
    "    elif pred_str.endswith('#place'):\n",
    "        articles[subj_str]['location'] = str(obj)\n",
    "\n",
    "# Convert dictionary to lists\n",
    "headlines = []\n",
    "descriptions = []\n",
    "categories = []\n",
    "locations = []\n",
    "\n",
    "for article_id, article_data in articles.items():\n",
    "    # Only include complete articles with all four fields\n",
    "    if all(key in article_data for key in ['headline', 'description', 'category', 'location']):\n",
    "        headlines.append(article_data['headline'])\n",
    "        descriptions.append(article_data['description'])\n",
    "        categories.append(article_data['category'])\n",
    "        locations.append(article_data['location'])\n",
    "\n",
    "print(f\"Extracted {len(headlines)} articles\")\n",
    "print(f\"Sample headline: {headlines[0] if headlines else 'None'}\")\n",
    "print(f\"Sample category: {categories[0] if categories else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total articles: 9999\n",
      "\n",
      "Category distribution:\n",
      "category\n",
      "SPORTS            1002\n",
      "WORLD NEWS        1001\n",
      "TRAVEL            1001\n",
      "FOOD & DRINK      1000\n",
      "STYLE & BEAUTY    1000\n",
      "WELLNESS           999\n",
      "PARENTING          999\n",
      "BUSINESS           999\n",
      "POLITICS           999\n",
      "ENTERTAINMENT      999\n",
      "Name: count, dtype: int64\n",
      "\n",
      "First 5 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mariano Rivera Sand Sculpture: Rays Give Yanke...</td>\n",
       "      <td>Yankees closer Mariano Rivera received another...</td>\n",
       "      <td>SPORTS</td>\n",
       "      <td>Torrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Real Snack Food Story</td>\n",
       "      <td>Youth Radio/Youth Media International (YMI) is...</td>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Santa Monica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Twitter Employee, Claire Diaz-Ortiz, Live Twee...</td>\n",
       "      <td>Yet, it seemed like the appropriate thing for ...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>Inglewood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Are you Parenting Like Your Parent?</td>\n",
       "      <td>Have you ever had one of those moments where y...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>Torrance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chipotle Doesn't Know When Carnitas Shortage W...</td>\n",
       "      <td>The hottest fast food chain in the country has...</td>\n",
       "      <td>BUSINESS</td>\n",
       "      <td>Pasadena</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline  \\\n",
       "0  Mariano Rivera Sand Sculpture: Rays Give Yanke...   \n",
       "1                          The Real Snack Food Story   \n",
       "2  Twitter Employee, Claire Diaz-Ortiz, Live Twee...   \n",
       "3                Are you Parenting Like Your Parent?   \n",
       "4  Chipotle Doesn't Know When Carnitas Shortage W...   \n",
       "\n",
       "                                         description   category      location  \n",
       "0  Yankees closer Mariano Rivera received another...     SPORTS      Torrance  \n",
       "1  Youth Radio/Youth Media International (YMI) is...   WELLNESS  Santa Monica  \n",
       "2  Yet, it seemed like the appropriate thing for ...  PARENTING     Inglewood  \n",
       "3  Have you ever had one of those moments where y...  PARENTING      Torrance  \n",
       "4  The hottest fast food chain in the country has...   BUSINESS      Pasadena  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    'headline': headlines,\n",
    "    'description': descriptions,\n",
    "    'category': categories,\n",
    "    'location': locations\n",
    "})\n",
    "\n",
    "print(f\"Total articles: {len(df)}\")\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(df['category'].value_counts())\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Headlines Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model 1: Headlines Only\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Model 1: Headlines Only\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert headlines to numerical features\n",
    "vectorizer1 = TfidfVectorizer(max_features=1000)\n",
    "X1 = vectorizer1.fit_transform(df['headline'])\n",
    "y = df['category']\n",
    "\n",
    "# Split into training (70%) and testing (30%) sets\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.5873 (58.73%)\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      BUSINESS       0.53      0.46      0.49       301\n",
      " ENTERTAINMENT       0.58      0.47      0.52       321\n",
      "  FOOD & DRINK       0.62      0.65      0.63       302\n",
      "     PARENTING       0.59      0.66      0.62       310\n",
      "      POLITICS       0.46      0.56      0.50       260\n",
      "        SPORTS       0.71      0.71      0.71       296\n",
      "STYLE & BEAUTY       0.71      0.73      0.72       302\n",
      "        TRAVEL       0.52      0.58      0.55       288\n",
      "      WELLNESS       0.53      0.50      0.51       324\n",
      "    WORLD NEWS       0.63      0.57      0.60       296\n",
      "\n",
      "      accuracy                           0.59      3000\n",
      "     macro avg       0.59      0.59      0.59      3000\n",
      "  weighted avg       0.59      0.59      0.59      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Multinomial Naive Bayes classifier\n",
    "model1 = MultinomialNB()\n",
    "model1.fit(X1_train, y1_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y1_pred = model1.predict(X1_test)\n",
    "accuracy1 = accuracy_score(y1_test, y1_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy: {accuracy1:.4f} ({accuracy1*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y1_test, y1_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Descriptions Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Model 2: Descriptions Only\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Model 2: Descriptions Only\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Convert descriptions to numerical features\n",
    "vectorizer2 = TfidfVectorizer(max_features=1000)\n",
    "X2 = vectorizer2.fit_transform(df['description'])\n",
    "\n",
    "# Split into training and testing sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.4983 (49.83%)\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "      BUSINESS       0.51      0.46      0.49       301\n",
      " ENTERTAINMENT       0.52      0.31      0.39       321\n",
      "  FOOD & DRINK       0.48      0.61      0.53       302\n",
      "     PARENTING       0.49      0.55      0.52       310\n",
      "      POLITICS       0.41      0.44      0.42       260\n",
      "        SPORTS       0.57      0.60      0.58       296\n",
      "STYLE & BEAUTY       0.58      0.50      0.53       302\n",
      "        TRAVEL       0.47      0.49      0.48       288\n",
      "      WELLNESS       0.49      0.48      0.48       324\n",
      "    WORLD NEWS       0.49      0.55      0.52       296\n",
      "\n",
      "      accuracy                           0.50      3000\n",
      "     macro avg       0.50      0.50      0.50      3000\n",
      "  weighted avg       0.50      0.50      0.50      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train multinomial Naive Bayes classifier\n",
    "model2 = MultinomialNB()\n",
    "model2.fit(X2_train, y2_train)\n",
    "\n",
    "# Make predictions on test set\n",
    "y2_pred = model2.predict(X2_test)\n",
    "accuracy2 = accuracy_score(y2_test, y2_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nAccuracy: {accuracy2:.4f} ({accuracy2*100:.2f}%)\")\n",
    "print(f\"\\nClassification Report:\")\n",
    "print(classification_report(y2_test, y2_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Combined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"Model 1: Headlines Only\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Combine headl\n",
    "df['combined'] = df['headline'] + \" \" + df['description']\n",
    "\n",
    "vectorizer3 = CountVectorizer()\n",
    "X3 = vectorizer3.fit_transform(df['combined'])\n",
    "\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = MultinomialNB()\n",
    "model3.fit(X3_train, y3_train)\n",
    "\n",
    "y3_pred = model3.predict(X3_test)\n",
    "accuracy3 = accuracy_score(y3_test, y3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine which model performed best and save it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
